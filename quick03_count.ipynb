{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfb5c7e-a4f8-4d88-94fc-9f248df745db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a71f58-af40-42bb-9b6b-f0baa94a37f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/site-packages (0.6.0)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', ConnectionResetError(54, 'Connection reset by peer'))': /simple/tiktoken/\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/site-packages (from tiktoken) (2024.4.28)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cbd1994-754c-495e-923f-ea9055bfd42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6628effc-084c-4154-b9e9-4192eebc07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b71dc05-8092-48a5-b3ab-5e48890d34ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_core_bpe',\n",
       " '_encode_bytes',\n",
       " '_encode_only_native_bpe',\n",
       " '_encode_single_piece',\n",
       " '_mergeable_ranks',\n",
       " '_pat_str',\n",
       " '_special_tokens',\n",
       " 'decode',\n",
       " 'decode_batch',\n",
       " 'decode_bytes',\n",
       " 'decode_bytes_batch',\n",
       " 'decode_single_token_bytes',\n",
       " 'decode_tokens_bytes',\n",
       " 'decode_with_offsets',\n",
       " 'encode',\n",
       " 'encode_batch',\n",
       " 'encode_ordinary',\n",
       " 'encode_ordinary_batch',\n",
       " 'encode_single_token',\n",
       " 'encode_with_unstable',\n",
       " 'eot_token',\n",
       " 'max_token_value',\n",
       " 'n_vocab',\n",
       " 'name',\n",
       " 'special_tokens_set',\n",
       " 'token_byte_values']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ecoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e98f3c-9ff2-4dcd-becf-2a058c956b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cl100k_base'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecoding.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef64f7a-dfd0-4fd0-9a66-0aa80ff68ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "779f40d0-c709-42dd-a15c-bfce19f430a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cl100k_base'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e2f656-2fc8-4996-b5ad-73e160430e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85315, 109, 27479, 48864, 18259, 254, 72456]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"深度学习网络\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1047e977-3a24-4e3f-8f98-68cc2ff9d6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'深度学习网络'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode([85315, 109, 27479, 48864, 18259, 254, 72456])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b847c38-4977-429a-8a1d-6df996e1ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(encode_str:str,encoding_name=\"cl100k_base\") -> int:\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    return len(encoding.encode(encode_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b111ddf-5297-4997-97f3-28990fd8bba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(\"long long ago\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc9d3873-9216-48d1-bc28-71ea4707b856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[998, 387, 477, 539, 311, 387]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"to be or not to be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6bdb32c-271d-47da-be8d-33cfefe7228a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'to', b' be', b' or', b' not', b' to', b' be']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[enc.decode_single_token_bytes(t) for t in [998, 387, 477, 539, 311, 387]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30f16ecf-8eaf-43e2-8fe4-1de542715741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_encodings(encode_str:str) -> None:\n",
    "    print(f\"\\nExample str:'{encode_str}'\")\n",
    "    for enc_name in [\"gpt2\", \"p50k_base\", \"cl100k_base\"]:\n",
    "        enc = tiktoken.get_encoding(enc_name)\n",
    "        token_ints = enc.encode(encode_str)\n",
    "        num_token = len(token_ints)\n",
    "        token_bytes = [enc.decode_single_token_bytes(t) for t in token_ints]\n",
    "        print(\"\")\n",
    "        print(f\"{enc_name}: {num_token} tokens\")\n",
    "        print(f\"token integers: {token_ints}\")\n",
    "        print(f\"token bytes: {token_bytes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f597cc7d-f8a5-4aab-944d-9b8125ed9549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example str:'antidisestablishmentarianism'\n",
      "\n",
      "gpt2: 5 tokens\n",
      "token integers: [415, 29207, 44390, 3699, 1042]\n",
      "token bytes: [b'ant', b'idis', b'establishment', b'arian', b'ism']\n",
      "\n",
      "p50k_base: 5 tokens\n",
      "token integers: [415, 29207, 44390, 3699, 1042]\n",
      "token bytes: [b'ant', b'idis', b'establishment', b'arian', b'ism']\n",
      "\n",
      "cl100k_base: 6 tokens\n",
      "token integers: [519, 85342, 34500, 479, 8997, 2191]\n",
      "token bytes: [b'ant', b'idis', b'establish', b'ment', b'arian', b'ism']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"antidisestablishmentarianism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92503d7e-2d4c-4daa-b823-663ddea4d57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example str:'北京欢迎你'\n",
      "\n",
      "gpt2: 11 tokens\n",
      "token integers: [44293, 245, 12859, 105, 162, 105, 95, 32573, 236, 19526, 254]\n",
      "token bytes: [b'\\xe5\\x8c', b'\\x97', b'\\xe4\\xba', b'\\xac', b'\\xe6', b'\\xac', b'\\xa2', b'\\xe8\\xbf', b'\\x8e', b'\\xe4\\xbd', b'\\xa0']\n",
      "\n",
      "p50k_base: 11 tokens\n",
      "token integers: [44293, 245, 12859, 105, 162, 105, 95, 32573, 236, 19526, 254]\n",
      "token bytes: [b'\\xe5\\x8c', b'\\x97', b'\\xe4\\xba', b'\\xac', b'\\xe6', b'\\xac', b'\\xa2', b'\\xe8\\xbf', b'\\x8e', b'\\xe4\\xbd', b'\\xa0']\n",
      "\n",
      "cl100k_base: 6 tokens\n",
      "token integers: [70090, 25340, 95, 10287, 236, 57668]\n",
      "token bytes: [b'\\xe5\\x8c\\x97\\xe4\\xba\\xac', b'\\xe6\\xac', b'\\xa2', b'\\xe8\\xbf', b'\\x8e', b'\\xe4\\xbd\\xa0']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"北京欢迎你\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f2dbb79-a7f7-4d8b-9255-4fd681ce21ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
       " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
       " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
       " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
       " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
       " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
       " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
       " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-1106-vision-preview', created=1711473033, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
       " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
       " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
       " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
       " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "models.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9b80c75-c106-4aee-b81a-f11a8d788cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages:str, model=\"gpt-3.5-turbo\"):\n",
    "    #models = client.models.list()\n",
    "    #current_models = [m.id for m in models]\n",
    "    #print(current_models)\n",
    "    try:\n",
    "        enc= tiktoken.encoding_for_model(model)\n",
    "    except (KeyError,ValueError) as e:\n",
    "        # 如果模型没有找到，使用 cl100k_base 编码并给出警告\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model in {\n",
    "        \"gpt-3.5-turbo-0125\",\n",
    "        \"gpt-4-turbo-2024-04-09\",\n",
    "    }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        # 对于 gpt-3.5-turbo 模型可能会有更新，此处返回假设为 gpt-3.5-turbo-0613 的token数量，并给出警告\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0125\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        # 对于 gpt-4 模型可能会有更新，此处返回假设为 gpt-4-0613 的token数量，并给出警告\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-turbo-2024-04-09\")\n",
    "    else:\n",
    "        # 对于没有实现的模型，抛出未实现错误\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    # 计算每条消息的token数\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(enc.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # 每条回复都以助手为首\n",
    "    return num_tokens\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e61abb25-8826-4998-8a14-630ed8980ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n",
      "Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\n",
      "25 prompt tokens counted by num_tokens_from_messages().\n",
      "25 prompt tokens counted by the OpenAI API.\n",
      "\n",
      "gpt-4-turbo-2024-04-09\n",
      "25 prompt tokens counted by num_tokens_from_messages().\n",
      "25 prompt tokens counted by the OpenAI API.\n",
      "\n",
      "gpt-4\n",
      "Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\n",
      "25 prompt tokens counted by num_tokens_from_messages().\n",
      "25 prompt tokens counted by the OpenAI API.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful, pattern-following assistant that translates corporate jargon into plain English.\",\n",
    "    }\n",
    "]\n",
    "for model in [\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"gpt-4-turbo-2024-04-09\",\n",
    "    \"gpt-4\",\n",
    "    ]:\n",
    "    print(model)\n",
    "    print(f\"{num_tokens_from_messages(example_messages,model)} prompt tokens counted by num_tokens_from_messages().\")\n",
    "    \n",
    "\n",
    "    complt = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=example_messages,\n",
    "        temperature=0,\n",
    "        max_tokens=1,# we're only counting input tokens here, so let's not waste tokens on the output\n",
    "    )\n",
    "    print(f'{complt.usage.prompt_tokens} prompt tokens counted by the OpenAI API.')\n",
    "    print(\"\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd89294-a7ef-49d5-9220-4b7dedeba55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
