{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ba4d4c-b686-4b53-86c6-c7ebf20942b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfae56ae-aa63-481b-93d7-2c070fc7236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e702d920-9793-49bb-b4d2-9e027ca6b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2be64ca-6d07-4a69-b99f-6d2df30d0d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
       " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
       " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
       " Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
       " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'),\n",
       " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
       " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
       " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
       " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
       " Model(id='gpt-4o', created=1715367049, object='model', owned_by='system')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed044d8-dcbb-4720-ac05-5809fa7f218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;31m\u001b[Klangchain\u001b[m\u001b[K                                0.2.6\n",
      "\u001b[01;31m\u001b[Klangchain\u001b[m\u001b[K-community                      0.0.36\n",
      "\u001b[01;31m\u001b[Klangchain\u001b[m\u001b[K-core                           0.2.11\n",
      "\u001b[01;31m\u001b[Klangchain\u001b[m\u001b[K-text-splitters                 0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip list |grep langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ccc1dbc-38e8-4aba-b70d-269a9737c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684368be-dfea-4458-b984-37385ebac37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a39e2a-6477-4de9-89d3-f3a46bc1a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e421bd0-1e59-4461-bbe4-3b4643f50211",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct-0914\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7bccfe5-2bc8-42d4-9226-37a871b30dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. \"为什么程序员总是喜欢住在一楼？因为他们不喜欢把楼梯赋值给自己！\"\n",
      "\n",
      "2. \"为什么程序员总是喜欢用旧手机？因为他们喜欢回顾自己的代码历史！\"\n",
      "\n",
      "3. \"为什么程序员总是喜欢喝咖啡？因为他们需要一种强大的刺激来保持清醒，以解决所有的bug！\"\n",
      "\n",
      "4. \"为什么程序员总是喜欢在凌晨3点工作？因为他们喜欢在'黑客'的时间内工作！\"\n",
      "\n",
      "5. \"为什么程序员总是喜欢在电脑前坐着？因为他们不喜欢被人打断他们的思维线程！\"\n"
     ]
    }
   ],
   "source": [
    "print(llm(\"讲5个程序员听得笑话\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aead03b-f632-4827-85dd-b4f9d1314600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b4e8cf5-438b-433e-87c0-6bfb9ab5a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.max_tokens=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7cf78e3e-ff49-44b1-b0cc-39c916c2964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4e24d72-a95a-42a6-ae51-8eaeec3835aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8c3e78c-462c-4e67-ae83-a268a2554695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    " AIMessage,\n",
    " HumanMessage,\n",
    " SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1466a60c-8df1-4123-a483-103543d3bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = [SystemMessage(content=\"你是个生活小帮手\"),\n",
    "       HumanMessage(content=\"欧洲杯总共有几支球队参加？\"),\n",
    "       AIMessage(content=\"16支\"),\n",
    "       HumanMessage(content=\"8强队伍都有哪些国家？\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52b7a280-5c00-4ebf-9651-9f72ce788e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是个生活小帮手'), HumanMessage(content='欧洲杯总共有几支球队参加？'), AIMessage(content='16支'), HumanMessage(content='8强队伍都有哪些国家？')]\n"
     ]
    }
   ],
   "source": [
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c08276ab-fc12-4236-94bc-21e49f6452ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result = chat_model(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78af6b6b-89eb-4ad8-b6e8-b8ba2ec277c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddac6fdc-5f46-4475-aad2-0e54e62e8138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "628c2212-c200-4330-8875-21e1e6b7c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcdbe30e-3ff5-46e6-b1e1-db009666d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(adjective=\"funny\",content=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "982e12d5-cce7-431f-91cc-a9d1dcaad695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a funny joke about chickens\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b80401e-57e6-4989-8019-0feda32b9f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['adjective', 'content'] template='Tell me a {adjective} joke about {content}'\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17edefe1-fc21-4eb6-a5a3-e5bfc9ff876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_tp = PromptTemplate.from_template(\n",
    "    \"生成可执行的快速排序代 {plg} 代码\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f2afff9-2ffa-477d-959a-a8f724f6ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct-0914\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "900ca125-006e-41ba-b314-33d1b85ff2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```\n",
      "package main\n",
      "import \"fmt\"\n",
      "func main() {\n",
      "    items := []int{9, 8, 7, 6, 5, 4, 3, 2, 1}\n",
      "    QuickSort(items, 0, len(items)-1)\n",
      "    fmt.Println(items)\n",
      "}\n",
      "func QuickSort(items []int, left, right int) {\n",
      "    if left < right {\n",
      "        pivot := partition(items, left, right)\n",
      "        QuickSort(items, left, pivot-1)\n",
      "        QuickSort(items, pivot+1, right)\n",
      "    }\n",
      "}\n",
      "func partition(items []int, left, right int) int {\n",
      "    pivot := items[right]\n",
      "    i := left - 1\n",
      "    for j := left; j < right; j++ {\n",
      "        if items[j] < pivot {\n",
      "            i++\n",
      "            items[i], items[j] = items[j], items[i]\n",
      "        }\n",
      "    }\n",
      "    items[i+1], items[right] = items[right], items[i+1]\n",
      "    return i + 1\n",
      "}\n",
      "```\n",
      "\n",
      "输出结果为[1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(llm(sort_tp.format(plg=\"golang\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f4119bb-f380-435e-a2a8-ebaa9a6fb38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e545facc-1a32-4b90-aff7-f4e6212ec2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\",\"Hello, how are you doing?\"),\n",
    "    (\"ai\",\"I'm doing well, thanks!\"),\n",
    "    (\"human\",\"{user_input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7709bdf1-f0a1-45f3-8c37-77b68dc1a6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['name', 'user_input'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], template='You are a helpful AI bot. Your name is {name}.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Hello, how are you doing?')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"I'm doing well, thanks!\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], template='{user_input}'))]\n"
     ]
    }
   ],
   "source": [
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13454d6a-2079-4b4a-aec6-0ec7389eda98",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = tmp.format_messages(\n",
    "    name=\"tom\",\n",
    "    user_input=\"What is you name?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc329577-e8b5-4bfd-b49f-ed4906d55490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='My name is Tom. How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 50, 'total_tokens': 62}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4e0a67bf-1f46-4b66-8bb7-53b17f66af4f-0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "546907bc-3062-4763-8585-f20bb360600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI bot. Your name is tom.\n",
      "What is you name?\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)\n",
    "print(messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a77b5a80-7731-4b8d-a5e0-d04d7ea73fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatTongyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "759d4ba6-3043-4f27-9cf5-d6a4218ac3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "examples = [\n",
    "  {\n",
    "    \"question\": \"谁活得更久，穆罕默德·阿里还是艾伦·图灵？\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：穆罕默德·阿里去世时多大了？\n",
    "中间答案：穆罕默德·阿里去世时74岁。\n",
    "追问：艾伦·图灵去世时多大了？\n",
    "中间答案：艾伦·图灵去世时41岁。\n",
    "所以最终答案是：穆罕默德·阿里\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"craigslist的创始人是什么时候出生的？\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：谁是craigslist的创始人？\n",
    "中间答案：Craigslist是由Craig Newmark创办的。\n",
    "追问：Craig Newmark是什么时候出生的？\n",
    "中间答案：Craig Newmark出生于1952年12月6日。\n",
    "所以最终答案是：1952年12月6日\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"乔治·华盛顿的外祖父是谁？\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：谁是乔治·华盛顿的母亲？\n",
    "中间答案：乔治·华盛顿的母亲是Mary Ball Washington。\n",
    "追问：Mary Ball Washington的父亲是谁？\n",
    "中间答案：Mary Ball Washington的父亲是Joseph Ball。\n",
    "所以最终答案是：Joseph Ball\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"《大白鲨》和《皇家赌场》的导演是同一个国家的吗？\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "这里需要进一步的问题吗：是的。\n",
    "追问：谁是《大白鲨》的导演？\n",
    "中间答案：《大白鲨》的导演是Steven Spielberg。\n",
    "追问：Steven Spielberg来自哪里？\n",
    "中间答案：美国。\n",
    "追问：谁是《皇家赌场》的导演？\n",
    "中间答案：《皇家赌场》的导演是Martin Campbell。\n",
    "追问：Martin Campbell来自哪里？\n",
    "中间答案：新西兰。\n",
    "所以最终答案是：不是\n",
    "\"\"\"\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aae0f1e1-5d8f-461f-a3ed-f41fef38a092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 谁活得更久，穆罕默德·阿里还是艾伦·图灵？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：穆罕默德·阿里去世时多大了？\n",
      "中间答案：穆罕默德·阿里去世时74岁。\n",
      "追问：艾伦·图灵去世时多大了？\n",
      "中间答案：艾伦·图灵去世时41岁。\n",
      "所以最终答案是：穆罕默德·阿里\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp = PromptTemplate(\n",
    "    input_variables=[\"question\",\"answer\"],\n",
    "    template=\"Question: {question}\\n{answer}\"\n",
    ")\n",
    "\n",
    "print (exp.format(**examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4c212ae-4e05-40ad-9598-ad98f8e7c025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['answer', 'question'] template='Question: {question}\\n{answer}'\n"
     ]
    }
   ],
   "source": [
    "print(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd27433e-5511-424d-b8ba-8ddfe659f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 《大白鲨》和《皇家赌场》的导演是同一个国家的吗？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：谁是《大白鲨》的导演？\n",
      "中间答案：《大白鲨》的导演是Steven Spielberg。\n",
      "追问：Steven Spielberg来自哪里？\n",
      "中间答案：美国。\n",
      "追问：谁是《皇家赌场》的导演？\n",
      "中间答案：《皇家赌场》的导演是Martin Campbell。\n",
      "追问：Martin Campbell来自哪里？\n",
      "中间答案：新西兰。\n",
      "所以最终答案是：不是\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(exp.format(**examples[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb0953f0-12ee-40bf-ba8b-d79412f21305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e133336-6a4c-43f3-bc01-57abcdff5275",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=exp,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7b8a65d-838b-4c2d-8669-2c6d2350f384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 谁活得更久，穆罕默德·阿里还是艾伦·图灵？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：穆罕默德·阿里去世时多大了？\n",
      "中间答案：穆罕默德·阿里去世时74岁。\n",
      "追问：艾伦·图灵去世时多大了？\n",
      "中间答案：艾伦·图灵去世时41岁。\n",
      "所以最终答案是：穆罕默德·阿里\n",
      "\n",
      "\n",
      "Question: craigslist的创始人是什么时候出生的？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：谁是craigslist的创始人？\n",
      "中间答案：Craigslist是由Craig Newmark创办的。\n",
      "追问：Craig Newmark是什么时候出生的？\n",
      "中间答案：Craig Newmark出生于1952年12月6日。\n",
      "所以最终答案是：1952年12月6日\n",
      "\n",
      "\n",
      "Question: 乔治·华盛顿的外祖父是谁？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：谁是乔治·华盛顿的母亲？\n",
      "中间答案：乔治·华盛顿的母亲是Mary Ball Washington。\n",
      "追问：Mary Ball Washington的父亲是谁？\n",
      "中间答案：Mary Ball Washington的父亲是Joseph Ball。\n",
      "所以最终答案是：Joseph Ball\n",
      "\n",
      "\n",
      "Question: 《大白鲨》和《皇家赌场》的导演是同一个国家的吗？\n",
      "\n",
      "这里需要进一步的问题吗：是的。\n",
      "追问：谁是《大白鲨》的导演？\n",
      "中间答案：《大白鲨》的导演是Steven Spielberg。\n",
      "追问：Steven Spielberg来自哪里？\n",
      "中间答案：美国。\n",
      "追问：谁是《皇家赌场》的导演？\n",
      "中间答案：《皇家赌场》的导演是Martin Campbell。\n",
      "追问：Martin Campbell来自哪里？\n",
      "中间答案：新西兰。\n",
      "所以最终答案是：不是\n",
      "\n",
      "\n",
      "Question: 龙珠的作者是谁?\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input=\"龙珠的作者是谁?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29182056-415e-49fd-b1e4-ef2d502f03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19605fb9-d50a-46e4-97b3-44a97f219448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6a79530f-989e-4f5b-9835-c92bf7526db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b4d0fdc-f7c3-4267-95a1-eadfe5ac0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate,PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e3d98f0-2d59-4473-a165-f8329d31edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\",\"output\"],\n",
    "    template=\"Input: {input}\\n{output}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2dae505b-e702-42a8-927f-07ec84085856",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2da785f-6d57-4b22-bedf-7472737ebfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    OpenAIEmbeddings(),\n",
    "    Chroma,\n",
    "    k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce044d93-e0c8-426a-8936-3564d34a740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=exp_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ae396a3-1a4b-4491-84f8-e6dcf7a925db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "sad\n",
      "\n",
      "Input: worried\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(similar_prompt.format(adjective=\"worried\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5138faa5-f2eb-4562-8cca-abeb709fbd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "`from langchain_community.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3021a4ff-a505-4bca-a290-dddf77ceee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c96975b-f8ca-4ab1-8b44-2dbc6eb3d5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sour\n"
     ]
    }
   ],
   "source": [
    "print(llm(similar_prompt.format(adjective=\"sweet\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44e35f8b-3ea6-4013-8c0a-19e1003718b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4428f845-c2bf-4fcf-889d-ec75bcd649de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate,HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d959b76-4084-4267-a9e5-5bf07b598f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d00ef89-ad45-4006-af98-0f1f3b4cfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94d93953-f2b7-46a6-ba06-975d0f989643",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt_ins = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "06e02e1d-34af-4a76-8377-4bc42b3c71c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",  # 模板内容\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\":fmt_ins},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b5cf09fe-d136-45a2-95a6-a9b97320d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = prompt.format(subject=\"ice cream flavors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52338c0a-decb-418a-a438-b40af4a65d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List five ice cream flavors.\n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "print(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "00ce140d-7c01-446f-9aa8-5cde5cbd033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "670634f1-117e-4c54-8f0a-f5e4599e0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bba565d3-c909-4114-a9eb-1c4066a5cc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "chocolate, vanilla, strawberry, mint chocolate chip, cookies and cream\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "32ec070a-26f0-4b4e-b3ca-6e2ea776a859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chocolate',\n",
       " 'vanilla',\n",
       " 'strawberry',\n",
       " 'mint chocolate chip',\n",
       " 'cookies and cream']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a276556f-a2e1-4f41-88d0-8be0df1ab6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8dfd5444-e813-4516-9ded-6689d7cf7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9664c7c6-0c02-44a0-9a7e-2473bde2c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = DatetimeOutputParser()\n",
    "template = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "95522b12-c09e-43de-a574-be35d581bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    partial_variables={\"format_instructions\":output_parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "43769660-1d2a-4a38-9614-faab6ef895f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] partial_variables={'format_instructions': \"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1755-02-28T07:34:51.797127Z, 1515-02-09T06:39:36.844810Z, 1201-07-30T09:26:09.455132Z\\n\\nReturn ONLY this string, no other words!\"} template='Answer the users question:\\n\\n{question}\\n\\n{format_instructions}'\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ed6c5d27-e4b1-4c3b-82cf-d14d044f22c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the users question:\n",
      "\n",
      "around when was bitcoin founded?\n",
      "\n",
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 1755-02-28T07:34:51.797127Z, 1515-02-09T06:39:36.844810Z, 1201-07-30T09:26:09.455132Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(question=\"around when was bitcoin founded?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7020fb7c-1aaf-4c01-a703-bedba72372d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chanin = LLMChain(prompt=prompt,llm=OpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c71f967f-47ad-460a-9040-52fc918a9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chanin.run(\"around when was bitcoin founded?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0a5a5528-f288-4b72-af9d-49ec72278c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n2009-01-03T18:15:05.000000Z'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "92203670-15a3-46ef-9ec2-bd3b9223696b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2009, 1, 3, 18, 15, 5)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "738f2350-c788-4565-9afc-5b252adb2da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-01-03 18:15:05\n"
     ]
    }
   ],
   "source": [
    "print(output_parser.parse(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c8adf-1596-41b5-b76d-a664f9ba6a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
